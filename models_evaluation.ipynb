{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "c6cd45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/halladj/data_set/main/\"\n",
    "#LAPTOPS_PATH = os.path.join(\"datasets\", \"labtops\")\n",
    "LAPTOPS_PATH = os.path.join(\"test_datasets\", \"labtops\")\n",
    "\n",
    "#LAPTOPS_URL = DOWNLOAD_ROOT + \"datasets/laptops/done.csv\"\n",
    "LAPTOPS_URL = DOWNLOAD_ROOT + \"test_datasets/laptops/inhanced_test.csv\"\n",
    "\n",
    "def fetch_laptops_data(laptops_url = LAPTOPS_URL, laptops_path = LAPTOPS_PATH):\n",
    "    os.makedirs(laptops_path, exist_ok= True)\n",
    "    #file_path = os.path.join(laptops_path, \"done.csv\")\n",
    "    file_path = os.path.join(laptops_path, \"inhanced_test.csv\")\n",
    "    urllib.request.urlretrieve(laptops_url, file_path)\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_laptops_data(laptops_path = LAPTOPS_PATH):\n",
    "    #csv_path = os.path.join(laptops_path, \"done.csv\")\n",
    "    csv_path = os.path.join(laptops_path, \"inhanced_test.csv\")\n",
    "    return pd.read_csv(csv_path, dtype= category_cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "06ba60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = {item: 'category' for item in ['ram_type', 'cpu_number_identifier', 'brand', 'cpu_family'\n",
    "                                               , 'cpu_modifier',  'gpu_brand', 'gpu_number_identifier', 'gpu_words_identifier',\n",
    "                                               'screen_resolution', 'cpu_brand']}\n",
    "\n",
    "fetch_laptops_data()\n",
    "laptops= load_laptops_data()\n",
    "\n",
    "laptops[\"state\"].replace([\"new\", \"used\"], [True, False], inplace=True)\n",
    "laptops[\"touch_screen\"].replace([1, 0], [True, False], inplace=True)\n",
    "laptops[\"anti_glare\"].replace([1, 0], [True, False], inplace=True)\n",
    "#####\n",
    "#laptops[\"gpu_vram\"].replace([0], [None], inplace=True)\n",
    "#laptops[\"gpu_brand\"].replace([0], [None], inplace=True)\n",
    "#laptops[\"gpu_number_identifier\"].replace([0], [None], inplace=True)\n",
    "#laptops[\"gpu_words_identifier\"].replace([0], [None], inplace=True)\n",
    "#####\n",
    "\n",
    "laptops[\"cpu_frequency\"].replace([0, np.nan], inplace=True)\n",
    "laptops[\"ram_frequency\"].replace([0, np.nan], inplace=True)\n",
    "\n",
    "laptops.dtypes\n",
    "column_label= laptops[\"price\"]\n",
    "laptops=laptops.drop(columns=[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "f511821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops_category= laptops[['ram_type', 'brand', 'cpu_family', \"cpu_generation\",\n",
    "                           'cpu_modifier', 'gpu_brand', 'gpu_number_identifier', \n",
    "                           'gpu_words_identifier','screen_resolution', 'cpu_brand']]\n",
    "#remove cpu generation\n",
    "laptops_num= laptops.drop(columns=['ram_type','cpu_number_identifier', 'brand', 'cpu_family',\n",
    "                                   'cpu_modifier',  'gpu_brand', 'gpu_number_identifier', \n",
    "                                   'gpu_words_identifier','screen_resolution', 'cpu_brand'])\n",
    "\n",
    "#laptops_num= laptops_num.drop(columns=['Back-light', 'gpu_frequency'])\n",
    "laptops_num= laptops_num.drop(columns=['Back-light'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7465533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "b5ead6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data-set:  (501, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the data-set: \", laptops.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "50e72ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "## ONEHOTENCODING\n",
    "######\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "onehot_encoder= OneHotEncoder()\n",
    "laptops_category_encoded= onehot_encoder.fit_transform(laptops_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "76af8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "## NORMALIZATION\n",
    "######\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "num_pipeline_full= Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"MinMax_scaler\", MinMaxScaler()),\n",
    "    (\"standered_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "num_pipeline_minmax= Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"MinMax_scaler\", MinMaxScaler()),\n",
    "])\n",
    "\n",
    "num_pipeline_standard= Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standered_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "num_pipeline_imputer= Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "\n",
    "laptops_num_transformed= num_pipeline_imputer.fit_transform(laptops_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "48f253c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####\n",
    "## DATA VISUALIZING\n",
    "#####\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.DataFrame(laptops_num_transformed, columns=list(laptops_num.columns)).hist(bins=50, figsize= (20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "d9b4782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_att= list(category_cols.keys())\n",
    "num_att= list(laptops_num.columns)\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "\n",
    "column_label= column_label.values.reshape(501,1)\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "2ec91d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "## DATA SPLIT\n",
    "#####\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error \n",
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_percentage_error, median_absolute_error\n",
    "                                           \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def print_matrices(y_test, predictions):\n",
    "    print(\"Explained Variance Score: %.2f\" % explained_variance_score(y_test, predictions))\n",
    "    print(\"Max Error: %.2f\" % max_error(y_test, predictions))\n",
    "    print(\"Mean Absolute Error: %.2f\" % mean_absolute_error(y_test, predictions))\n",
    "    print(\"Mean Squared Error: %.2f\" % mean_squared_error(y_test, predictions))\n",
    "    print(\"Mean Absolute Precentage Error: %.2f\" % mean_absolute_percentage_error(y_test, predictions))\n",
    "    print(\"Median Absolute Error: %.2f\" % median_absolute_error(y_test, predictions))\n",
    "    print(\"R2 Score : %.2f\" % r2_score(y_test, predictions))\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "7dda56ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.77\n",
      "Max Error: 314238.92\n",
      "Mean Absolute Error: 26982.25\n",
      "Mean Squared Error: 2298886754.25\n",
      "Mean Absolute Precentage Error: 0.23\n",
      "Median Absolute Error: 14556.12\n",
      "R2 Score : 0.77\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Least Squars\n",
    "######\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "\n",
    "\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "9121e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2}\n",
      "0.7859256497159061\n",
      "Explained Variance Score: 0.79\n",
      "Max Error: 320768.12\n",
      "Mean Absolute Error: 25291.75\n",
      "Mean Squared Error: 2114436327.55\n",
      "Mean Absolute Precentage Error: 0.22\n",
      "Median Absolute Error: 15912.60\n",
      "R2 Score : 0.79\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Ridge\n",
    "\n",
    "######\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_minmax, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "ridge_params = {'alpha':[1,2,3,4,5]}\n",
    "reg= Ridge()\n",
    "grid = GridSearchCV(reg, param_grid=ridge_params, cv=5,scoring='r2')\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction= grid.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "53d6c176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.79\n",
      "Max Error: 322667.62\n",
      "Mean Absolute Error: 25458.01\n",
      "Mean Squared Error: 2158955168.35\n",
      "Mean Absolute Precentage Error: 0.22\n",
      "Median Absolute Error: 14219.11\n",
      "R2 Score : 0.78\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Ridge\n",
    "\n",
    "######\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_minmax, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= Ridge()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "46e3a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "# full_pipeline= ColumnTransformer([\n",
    "#     (\"num\", num_pipeline_minmax, num_att),\n",
    "#     (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "# ])\n",
    "# laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "# x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "# ridge_cv_params =\n",
    "# reg= Ridge()\n",
    "# grid = GridSearchCV(reg, param_grid=ridge_params, cv=5)\n",
    "# grid.fit(x_train, y_train)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "# reg=Ridge(2)\n",
    "# reg.fit(x_train, y_train)\n",
    "\n",
    "# prediction= reg.predict(x_test)\n",
    "# print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "0453d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.79\n",
      "Max Error: 322567.15\n",
      "Mean Absolute Error: 25396.40\n",
      "Mean Squared Error: 2150815835.43\n",
      "Mean Absolute Precentage Error: 0.22\n",
      "Median Absolute Error: 14368.30\n",
      "R2 Score : 0.79\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## RidgeCV\n",
    "\n",
    "######\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_minmax, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "a48ef78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.79\n",
      "Max Error: 323736.06\n",
      "Mean Absolute Error: 25426.46\n",
      "Mean Squared Error: 2167608774.86\n",
      "Mean Absolute Precentage Error: 0.22\n",
      "Median Absolute Error: 14249.22\n",
      "R2 Score : 0.78\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## BayesianRidge\n",
    "######\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_minmax, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= BayesianRidge(alpha_1=1e-06, alpha_2=1e-06,lambda_1=1e-06, lambda_2=1e-06)\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "ac8da4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'l1_ratio': 0.99}\n",
      "0.7833759010565957\n",
      "Explained Variance Score: 0.78\n",
      "Max Error: 309243.08\n",
      "Mean Absolute Error: 28439.19\n",
      "Mean Squared Error: 2244196570.98\n",
      "Mean Absolute Precentage Error: 0.25\n",
      "Median Absolute Error: 18625.26\n",
      "R2 Score : 0.78\n"
     ]
    }
   ],
   "source": [
    "#ElasticNet\n",
    "#without built-in cross-validation\n",
    "from sklearn.linear_model import ElasticNet\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att) \n",
    "])\n",
    "\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "    \n",
    "params = {'alpha':[1.5,1,2,3,4,5],\n",
    "               'l1_ratio':[0.85,0.9,0.95,0.99]\n",
    "               }\n",
    "\n",
    "\n",
    "reg= ElasticNet()\n",
    "grid = GridSearchCV(reg, param_grid=params, cv=5,scoring='r2')\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction= grid.predict(x_test)\n",
    "print_matrices(y_test, prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "106f8e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74977151542.26537, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56507158398.44803, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89557007849.2019, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 89345937353.68271, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88982176754.49611, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88789250650.0103, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88654512354.008, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88597623398.60562, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88561241551.61761, tolerance: 296091175.9663987\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50284603016.351105, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61299391651.74387, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62585854830.14051, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63751705947.03543, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63181637046.49095, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61810398781.264465, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63396010466.87258, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63459119203.981155, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63478066890.921394, tolerance: 229580876.27064875\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 98081084118.52742, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1045586825.6162109, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68896973318.6915, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92319128319.22433, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92906746694.12088, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92834792571.23203, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92746162963.79048, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92712063545.59752, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92694097198.3313, tolerance: 312236246.82264876\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71793672246.60574, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70556794236.50786, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69860007421.18344, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69477288380.71663, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69254511393.54947, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69092476076.65448, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 69006992752.49081, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68943282448.37962, tolerance: 285599430.6333988\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75454295304.5511, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52146767532.61242, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75978098441.21132, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75469864252.5888, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75142831718.62132, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74936156065.82239, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74787351821.22023, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74706459599.32805, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:513: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 74645173049.2142, tolerance: 265052476.87187502\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.79\n",
      "Max Error: 319140.64\n",
      "Mean Absolute Error: 25729.34\n",
      "Mean Squared Error: 2159733914.59\n",
      "Mean Absolute Precentage Error: 0.23\n",
      "Median Absolute Error: 14445.63\n",
      "R2 Score : 0.78\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## ElasticNetCV\n",
    "######\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_imputer, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= ElasticNetCV(max_iter=6000,l1_ratio=1,cv=5, random_state=0, alphas=[\n",
    "                       0.0125, 0.025, 0.05, .125, .25, .5, 1., 2., 4.])\n",
    "reg.fit(x_train, y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "97bbf61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=3.901e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.437e+02, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.196e+02, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=2.236e+06, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=1.946e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=6.773e+05, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=2.055e+05, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.763e+02, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.242e+02, with an active set of 97 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=4.747e+02, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=7.460e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=1.635e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=2.477e+04, with an active set of 172 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=1.415e+04, with an active set of 172 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=4.797e+03, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=9.097e+03, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 124 iterations, i.e. alpha=9.963e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=3.142e+09, with an active set of 171 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=7.896e+08, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=2.881e+08, with an active set of 171 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=8.541e+02, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=8.494e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=8.438e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=9.014e+03, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=8.221e+06, with an active set of 164 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=8.220e+06, with an active set of 165 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=7.013e+06, with an active set of 169 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.426e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.648e+02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.403e+02, with an active set of 64 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.782e+02, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.754e+02, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=1.751e+02, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.490e+03, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=3.834e+05, with an active set of 149 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=7.962e+06, with an active set of 165 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=7.420e+06, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=6.696e+06, with an active set of 167 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=4.520e+06, with an active set of 169 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=3.406e+06, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=2.942e+05, with an active set of 173 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=2.942e+05, with an active set of 174 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.331e+02, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=1.305e+03, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.097e+04, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=2.096e+04, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=3.656e+04, with an active set of 134 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=1.219e+07, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=6.534e+06, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=5.432e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.405e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=2.737e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=2.124e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=1.180e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.624e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.624e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=7.410e+02, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.116e+03, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.278e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=9.978e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=9.620e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=3.660e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=2.816e+06, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=7.536e+06, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=3.089e+08, with an active set of 144 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.927e+10, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.981e+11, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=2.622e+11, with an active set of 171 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=1.304e+11, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=3.555e+10, with an active set of 175 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.581e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.369e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=2.819e+03, with an active set of 85 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.901e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.901e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=2.895e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 143 iterations, i.e. alpha=8.408e+03, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.71\n",
      "Max Error: 339050.89\n",
      "Mean Absolute Error: 33270.03\n",
      "Mean Squared Error: 2966171093.42\n",
      "Mean Absolute Precentage Error: 0.28\n",
      "Median Absolute Error: 18713.66\n",
      "R2 Score : 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=1.200e+04, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=4.765e+04, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=1.287e+06, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=8.060e+05, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=5.467e+05, with an active set of 169 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=4.555e+05, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=3.380e+05, with an active set of 170 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=1.690e+05, with an active set of 170 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=6.157e+04, with an active set of 170 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=4.408e+04, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=2.414e+04, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=7.089e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.872e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=4.744e+02, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=3.645e+03, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=3.641e+03, with an active set of 56 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.935e+03, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.865e+04, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.886e+04, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=2.141e+11, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=1.523e+11, with an active set of 176 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:615: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=1.418e+11, with an active set of 176 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## LarsCV\n",
    "######\n",
    "from sklearn.linear_model import LarsCV\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_standard, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "reg= LarsCV(cv=10, normalize=False)\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "80725d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48266461295.234474, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29439036154.93953, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17527459834.566025, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54116481916.45088, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61428230464.86077, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63086458273.058105, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63819537449.133865, tolerance: 220431285.7395987\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 55725162089.61412, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45204452652.75073, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23471893364.07057, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36659305688.25569, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70089972459.60306, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75107885567.14978, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77120814235.20688, tolerance: 284480766.20573205\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50690762571.788895, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54626790658.495026, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56690321821.77702, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60808613088.31903, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65863458451.879395, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68683598341.51286, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70549357561.30174, tolerance: 282971275.39479864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39890341422.548904, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27468286041.78708, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4516228158.000763, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45132209618.563286, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60433799350.89367, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63263796204.67387, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64457490268.95545, tolerance: 253836681.66666672\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.79\n",
      "Max Error: 315496.76\n",
      "Mean Absolute Error: 25581.74\n",
      "Mean Squared Error: 2142877790.29\n",
      "Mean Absolute Precentage Error: 0.23\n",
      "Median Absolute Error: 14113.34\n",
      "R2 Score : 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81264455010.8639, tolerance: 347320007.98479897\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## LassoCV\n",
    "######\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= LassoCV(cv=4, n_alphas=50,alphas=[\n",
    "                       0.0125, 0.025, 0.05, .125, .25, .5, 1.])\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "3d13b9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.68\n",
      "Max Error: 330043.28\n",
      "Mean Absolute Error: 36439.50\n",
      "Mean Squared Error: 3218057230.33\n",
      "Mean Absolute Precentage Error: 0.31\n",
      "Median Absolute Error: 24902.69\n",
      "R2 Score : 0.68\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## OrthogonalMatchingPursuitCV\n",
    "######\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= OrthogonalMatchingPursuitCV(cv=4, normalize=False)\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "93033b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.68\n",
      "Max Error: 330288.82\n",
      "Mean Absolute Error: 36662.17\n",
      "Mean Squared Error: 3194887971.28\n",
      "Mean Absolute Precentage Error: 0.32\n",
      "Median Absolute Error: 22365.20\n",
      "R2 Score : 0.68\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## ARDRegression\n",
    "######\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_imputer, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= ARDRegression()\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "1d069b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.77\n",
      "Max Error: 339500.00\n",
      "Mean Absolute Error: 24281.69\n",
      "Mean Squared Error: 2344253133.67\n",
      "Mean Absolute Precentage Error: 0.21\n",
      "Median Absolute Error: 10000.00\n",
      "R2 Score : 0.77\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## KNeighborsRegressor\n",
    "######\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_minmax, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "reg= KNeighborsRegressor(n_neighbors=2)\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "af26143c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 4}\n",
      "0.6950459108231439\n",
      "Explained Variance Score: 0.72\n",
      "Max Error: 372025.00\n",
      "Mean Absolute Error: 28354.96\n",
      "Mean Squared Error: 2885403168.33\n",
      "Mean Absolute Precentage Error: 0.22\n",
      "Median Absolute Error: 15250.00\n",
      "R2 Score : 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_minmax, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "params = {'n_neighbors':[1,2,3,4,5,6,7,8,9]}\n",
    "reg= KNeighborsRegressor()\n",
    "grid = GridSearchCV(reg, param_grid=params, cv=5,scoring='r2')\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction= grid.predict(x_test)\n",
    "print_matrices(y_test, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "6be4eb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.78\n",
      "Max Error: 305106.23\n",
      "Mean Absolute Error: 29215.30\n",
      "Mean Squared Error: 2199055878.60\n",
      "Mean Absolute Precentage Error: 0.26\n",
      "Median Absolute Error: 20596.42\n",
      "R2 Score : 0.78\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "## MLPRegressor\n",
    "######\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_imputer, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "    \n",
    "reg=MLPRegressor(random_state=0, max_iter=100000)\n",
    "reg.fit(x_train.todense(), y_train.ravel())\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "1033e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'epsilon': 0.125}\n",
      "0.5908796911007592\n",
      "Explained Variance Score: 0.53\n",
      "Max Error: 454819.01\n",
      "Mean Absolute Error: 39701.40\n",
      "Mean Squared Error: 4746518620.02\n",
      "Mean Absolute Precentage Error: 0.31\n",
      "Median Absolute Error: 20378.59\n",
      "R2 Score : 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "## LinearSVR\n",
    "#######\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_imputer, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att)\n",
    "    \n",
    "])\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "params = {'C': [0.01, 0.1, 1, 10,15, 100 ],\n",
    "          'epsilon':[0.1,0.125,0.2]\n",
    "         }\n",
    "reg= LinearSVR()\n",
    "grid = GridSearchCV(reg, param_grid=params, cv=5,scoring='r2')\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "\n",
    "prediction= grid.predict(x_test)\n",
    "print_matrices(y_test, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "7eed52f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.00\n",
      "Max Error: 543472.14\n",
      "Mean Absolute Error: 66707.62\n",
      "Mean Squared Error: 10735701089.76\n",
      "Mean Absolute Precentage Error: 0.46\n",
      "Median Absolute Error: 46462.81\n",
      "R2 Score : -0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "## SVR\n",
    "#######\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att) \n",
    "])\n",
    "\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "    \n",
    "reg= SVR()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "10bae011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.00\n",
      "Max Error: 488496.28\n",
      "Mean Absolute Error: 82980.32\n",
      "Mean Squared Error: 10837460630.93\n",
      "Mean Absolute Precentage Error: 0.73\n",
      "Median Absolute Error: 73496.00\n",
      "R2 Score : -0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "## NuSVR\n",
    "#######\n",
    "from sklearn.svm import NuSVR\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att) \n",
    "])\n",
    "\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "    \n",
    "reg= NuSVR(C=1.0, nu=0.1)\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "817c3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.75\n",
      "Max Error: 290055.56\n",
      "Mean Absolute Error: 30223.25\n",
      "Mean Squared Error: 2494652013.38\n",
      "Mean Absolute Precentage Error: 0.25\n",
      "Median Absolute Error: 18250.00\n",
      "R2 Score : 0.75\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "## DecisionTreeRegressor\n",
    "#######\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att) \n",
    "])\n",
    "\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "    \n",
    "reg= DecisionTreeRegressor(random_state=0, max_depth=15,min_samples_leaf=10)\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)\n",
    "\n",
    "#plot_tree(reg)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "db7b4bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.85\n",
      "Max Error: 264000.00\n",
      "Mean Absolute Error: 20858.30\n",
      "Mean Squared Error: 1533758357.63\n",
      "Mean Absolute Precentage Error: 0.20\n",
      "Median Absolute Error: 11000.00\n",
      "R2 Score : 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att) \n",
    "])\n",
    "\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "    \n",
    "reg= ExtraTreeRegressor(splitter='random',random_state=0, max_depth=8,min_samples_split=5\n",
    "                        )\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)\n",
    "\n",
    "#plot_tree(reg)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "2f614ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.79\n",
      "Max Error: 289616.00\n",
      "Mean Absolute Error: 28435.58\n",
      "Mean Squared Error: 2139674719.79\n",
      "Mean Absolute Precentage Error: 0.25\n",
      "Median Absolute Error: 18460.77\n",
      "R2 Score : 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "full_pipeline= ColumnTransformer([\n",
    "    (\"num\", num_pipeline_full, num_att),\n",
    "    (\"categories\", OneHotEncoder(), category_att) \n",
    "])\n",
    "\n",
    "laptops_prepared= full_pipeline.fit_transform(laptops)\n",
    "x_train, x_test, y_train, y_test= train_test_split(laptops_prepared, column_label, test_size=0.2, random_state=1)\n",
    "    \n",
    "reg= SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "prediction= reg.predict(x_test)\n",
    "print_matrices(y_test, prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
